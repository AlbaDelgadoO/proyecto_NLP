{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241ac301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>messages</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>tokens</th>\n",
       "      <th>lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Germany!\\n\\nJust the person I want to speak wi...</td>\n",
       "      <td>germany just the person i want to speak with i...</td>\n",
       "      <td>['germany', 'person', 'want', 'speak', 'somewh...</td>\n",
       "      <td>['germany', 'person', 'want', 'speak', 'somewh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You've whet my appetite, Italy. What's the sug...</td>\n",
       "      <td>you ve whet my appetite italy what s the sugge...</td>\n",
       "      <td>['ve', 'whet', 'appetite', 'italy', 's', 'sugg...</td>\n",
       "      <td>['ve', 'whet', 'appetite', 'italy', 's', 'sugg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>üëç</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It seems like there are a lot of ways that cou...</td>\n",
       "      <td>it seems like there are a lot of ways that cou...</td>\n",
       "      <td>['like', 'lot', 'ways', 'wrong', 'don', 't', '...</td>\n",
       "      <td>['like', 'lot', 'way', 'wrong', 'don', 't', 'f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yeah, I can‚Äôt say I‚Äôve tried it and it works, ...</td>\n",
       "      <td>yeah i can t say i ve tried it and it works ca...</td>\n",
       "      <td>['yeah', 't', 've', 'tried', 'works', 'cause',...</td>\n",
       "      <td>['yeah', 't', 've', 'try', 'work', 'cause', 'v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I am just sensing that you don‚Äôt like this ide...</td>\n",
       "      <td>i am just sensing that you don t like this ide...</td>\n",
       "      <td>['sensing', 'don', 't', 'like', 'idea', 'shall...</td>\n",
       "      <td>['sense', 'don', 't', 'like', 'idea', 'shall',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Any thoughts?</td>\n",
       "      <td>any thoughts</td>\n",
       "      <td>['thoughts']</td>\n",
       "      <td>['thought']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sorry Italy I've been away doing, um, German t...</td>\n",
       "      <td>sorry italy i ve been away doing um german thi...</td>\n",
       "      <td>['sorry', 'italy', 've', 'away', 'um', 'german...</td>\n",
       "      <td>['sorry', 'italy', 've', 'away', 'um', 'german...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I don't think I'm ready to go for that idea, h...</td>\n",
       "      <td>i don t think i m ready to go for that idea ho...</td>\n",
       "      <td>['don', 't', 'think', 'm', 'ready', 'idea', 'd...</td>\n",
       "      <td>['don', 't', 'think', 'm', 'ready', 'idea', 'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I am pretty conflicted about whether to guess ...</td>\n",
       "      <td>i am pretty conflicted about whether to guess ...</td>\n",
       "      <td>['pretty', 'conflicted', 'guess', 'telling', '...</td>\n",
       "      <td>['pretty', 'conflicted', 'guess', 'tell', 'tru...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            messages  \\\n",
       "0  Germany!\\n\\nJust the person I want to speak wi...   \n",
       "1  You've whet my appetite, Italy. What's the sug...   \n",
       "2                                                  üëç   \n",
       "3  It seems like there are a lot of ways that cou...   \n",
       "4  Yeah, I can‚Äôt say I‚Äôve tried it and it works, ...   \n",
       "5  I am just sensing that you don‚Äôt like this ide...   \n",
       "6                                      Any thoughts?   \n",
       "7  Sorry Italy I've been away doing, um, German t...   \n",
       "8  I don't think I'm ready to go for that idea, h...   \n",
       "9  I am pretty conflicted about whether to guess ...   \n",
       "\n",
       "                                          text_clean  \\\n",
       "0  germany just the person i want to speak with i...   \n",
       "1  you ve whet my appetite italy what s the sugge...   \n",
       "2                                                      \n",
       "3  it seems like there are a lot of ways that cou...   \n",
       "4  yeah i can t say i ve tried it and it works ca...   \n",
       "5  i am just sensing that you don t like this ide...   \n",
       "6                                       any thoughts   \n",
       "7  sorry italy i ve been away doing um german thi...   \n",
       "8  i don t think i m ready to go for that idea ho...   \n",
       "9  i am pretty conflicted about whether to guess ...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  ['germany', 'person', 'want', 'speak', 'somewh...   \n",
       "1  ['ve', 'whet', 'appetite', 'italy', 's', 'sugg...   \n",
       "2                                                 []   \n",
       "3  ['like', 'lot', 'ways', 'wrong', 'don', 't', '...   \n",
       "4  ['yeah', 't', 've', 'tried', 'works', 'cause',...   \n",
       "5  ['sensing', 'don', 't', 'like', 'idea', 'shall...   \n",
       "6                                       ['thoughts']   \n",
       "7  ['sorry', 'italy', 've', 'away', 'um', 'german...   \n",
       "8  ['don', 't', 'think', 'm', 'ready', 'idea', 'd...   \n",
       "9  ['pretty', 'conflicted', 'guess', 'telling', '...   \n",
       "\n",
       "                                              lemmas  \n",
       "0  ['germany', 'person', 'want', 'speak', 'somewh...  \n",
       "1  ['ve', 'whet', 'appetite', 'italy', 's', 'sugg...  \n",
       "2                                                 []  \n",
       "3  ['like', 'lot', 'way', 'wrong', 'don', 't', 'f...  \n",
       "4  ['yeah', 't', 've', 'try', 'work', 'cause', 'v...  \n",
       "5  ['sense', 'don', 't', 'like', 'idea', 'shall',...  \n",
       "6                                        ['thought']  \n",
       "7  ['sorry', 'italy', 've', 'away', 'um', 'german...  \n",
       "8  ['don', 't', 'think', 'm', 'ready', 'idea', 'd...  \n",
       "9  ['pretty', 'conflicted', 'guess', 'tell', 'tru...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Primero vemos algunas filas del texto preprocesado\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet(\"../data/train_preprocessed.parquet\")\n",
    "df.head(10)[[\"messages\", \"text_clean\", \"tokens\", \"lemmas\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a926a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulario BoW: 10434\n",
      "Vocabulario TF-IDF: 10434\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['germany',\n",
       " 'just',\n",
       " 'the',\n",
       " 'person',\n",
       " 'want',\n",
       " 'to',\n",
       " 'speak',\n",
       " 'with',\n",
       " 'have',\n",
       " 'somewhat',\n",
       " 'crazy',\n",
       " 'idea',\n",
       " 'that',\n",
       " 've',\n",
       " 'always',\n",
       " 'wanted',\n",
       " 'try',\n",
       " 'but',\n",
       " 'never',\n",
       " 'actually']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ahora vemos el tama√±o del vocabulario de los modelos BoW y TF-IDF\n",
    "import joblib\n",
    "cv = joblib.load(\"../diplomacy/models/representations/bow_vectorizer.joblib\")\n",
    "tfidf = joblib.load(\"../diplomacy/models/representations/tfidf_vectorizer.joblib\")\n",
    "\n",
    "print(\"Vocabulario BoW:\", len(cv.vocabulary_))\n",
    "print(\"Vocabulario TF-IDF:\", len(tfidf.vocabulary_))\n",
    "\n",
    "# Mostrar algunas palabras del vocabulario\n",
    "list(cv.vocabulary_.keys())[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c0dfd34",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "<class 'numpy.random._mt19937.MT19937'> is not a known BitGenerator module.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Vamos a ver ejemplos de embeddings Word2Vec\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgensim\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Word2Vec\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m w2v = \u001b[43mWord2Vec\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../diplomacy/models/embeddings/word2vec.model\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# N√∫mero de palabras aprendidas\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTama√±o del vocabulario Word2Vec:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(w2v.wv.key_to_index))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Oihane\\Desktop\\NLP\\Entrega2\\venv\\Lib\\site-packages\\gensim\\models\\word2vec.py:1953\u001b[39m, in \u001b[36mWord2Vec.load\u001b[39m\u001b[34m(cls, rethrow, *args, **kwargs)\u001b[39m\n\u001b[32m   1934\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Load a previously saved :class:`~gensim.models.word2vec.Word2Vec` model.\u001b[39;00m\n\u001b[32m   1935\u001b[39m \n\u001b[32m   1936\u001b[39m \u001b[33;03mSee Also\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1950\u001b[39m \n\u001b[32m   1951\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1952\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1953\u001b[39m     model = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mWord2Vec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1954\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, Word2Vec):\n\u001b[32m   1955\u001b[39m         rethrow = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Oihane\\Desktop\\NLP\\Entrega2\\venv\\Lib\\site-packages\\gensim\\utils.py:485\u001b[39m, in \u001b[36mSaveLoad.load\u001b[39m\u001b[34m(cls, fname, mmap)\u001b[39m\n\u001b[32m    481\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33mloading \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m object from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, \u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m, fname)\n\u001b[32m    483\u001b[39m compress, subname = SaveLoad._adapt_by_suffix(fname)\n\u001b[32m--> \u001b[39m\u001b[32m485\u001b[39m obj = \u001b[43munpickle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    486\u001b[39m obj._load_specials(fname, mmap, compress, subname)\n\u001b[32m    487\u001b[39m obj.add_lifecycle_event(\u001b[33m\"\u001b[39m\u001b[33mloaded\u001b[39m\u001b[33m\"\u001b[39m, fname=fname)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Oihane\\Desktop\\NLP\\Entrega2\\venv\\Lib\\site-packages\\gensim\\utils.py:1460\u001b[39m, in \u001b[36munpickle\u001b[39m\u001b[34m(fname)\u001b[39m\n\u001b[32m   1446\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Load object from `fname`, using smart_open so that `fname` can be on S3, HDFS, compressed etc.\u001b[39;00m\n\u001b[32m   1447\u001b[39m \n\u001b[32m   1448\u001b[39m \u001b[33;03mParameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1457\u001b[39m \n\u001b[32m   1458\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1459\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(fname, \u001b[33m'\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m-> \u001b[39m\u001b[32m1460\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_pickle\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlatin1\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Oihane\\Desktop\\NLP\\Entrega2\\venv\\Lib\\site-packages\\numpy\\random\\_pickle.py:34\u001b[39m, in \u001b[36m__bit_generator_ctor\u001b[39m\u001b[34m(bit_generator_name)\u001b[39m\n\u001b[32m     32\u001b[39m     bit_generator = BitGenerators[bit_generator_name]\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;28mstr\u001b[39m(bit_generator_name) + \u001b[33m'\u001b[39m\u001b[33m is not a known \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     35\u001b[39m                                                \u001b[33m'\u001b[39m\u001b[33mBitGenerator module.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m bit_generator()\n",
      "\u001b[31mValueError\u001b[39m: <class 'numpy.random._mt19937.MT19937'> is not a known BitGenerator module."
     ]
    }
   ],
   "source": [
    "# Vamos a ver ejemplos de embeddings Word2Vec\n",
    "from gensim.models import Word2Vec\n",
    "w2v = Word2Vec.load(\"../diplomacy/models/embeddings/word2vec.model\")\n",
    "\n",
    "# N√∫mero de palabras aprendidas\n",
    "print(\"Tama√±o del vocabulario Word2Vec:\", len(w2v.wv.key_to_index))\n",
    "\n",
    "# Ver los t√©rminos m√°s similares a una palabra\n",
    "w2v.wv.most_similar(\"support\", topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d57ad64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'\",\n",
       " ' ',\n",
       " ',',\n",
       " 'e',\n",
       " 'n',\n",
       " 'a',\n",
       " 't',\n",
       " 'i',\n",
       " 's',\n",
       " 'r',\n",
       " 'o',\n",
       " 'l',\n",
       " 'g',\n",
       " 'd',\n",
       " 'u',\n",
       " 'p',\n",
       " 'c',\n",
       " 'y',\n",
       " 'h',\n",
       " 'm',\n",
       " '[',\n",
       " ']',\n",
       " 'k',\n",
       " 'b',\n",
       " 'f',\n",
       " 'w',\n",
       " 'v',\n",
       " 'x',\n",
       " 'z',\n",
       " 'q',\n",
       " 'j']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ver tama√±o y primeras palabras\n",
    "len(w2v.wv.key_to_index)\n",
    "list(w2v.wv.key_to_index.keys())[:50]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98db8d51",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "<class 'numpy.random._mt19937.MT19937'> is not a known BitGenerator module.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgensim\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Word2Vec\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m w2v = \u001b[43mWord2Vec\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../diplomacy/models/embeddings/word2vec.model\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(w2v.wv.key_to_index))\n\u001b[32m      5\u001b[39m \u001b[38;5;28mlist\u001b[39m(w2v.wv.key_to_index.keys())[:\u001b[32m50\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Oihane\\Desktop\\NLP\\Entrega2\\venv\\Lib\\site-packages\\gensim\\models\\word2vec.py:1953\u001b[39m, in \u001b[36mWord2Vec.load\u001b[39m\u001b[34m(cls, rethrow, *args, **kwargs)\u001b[39m\n\u001b[32m   1934\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Load a previously saved :class:`~gensim.models.word2vec.Word2Vec` model.\u001b[39;00m\n\u001b[32m   1935\u001b[39m \n\u001b[32m   1936\u001b[39m \u001b[33;03mSee Also\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1950\u001b[39m \n\u001b[32m   1951\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1952\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1953\u001b[39m     model = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mWord2Vec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1954\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, Word2Vec):\n\u001b[32m   1955\u001b[39m         rethrow = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Oihane\\Desktop\\NLP\\Entrega2\\venv\\Lib\\site-packages\\gensim\\utils.py:485\u001b[39m, in \u001b[36mSaveLoad.load\u001b[39m\u001b[34m(cls, fname, mmap)\u001b[39m\n\u001b[32m    481\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33mloading \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m object from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, \u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m, fname)\n\u001b[32m    483\u001b[39m compress, subname = SaveLoad._adapt_by_suffix(fname)\n\u001b[32m--> \u001b[39m\u001b[32m485\u001b[39m obj = \u001b[43munpickle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    486\u001b[39m obj._load_specials(fname, mmap, compress, subname)\n\u001b[32m    487\u001b[39m obj.add_lifecycle_event(\u001b[33m\"\u001b[39m\u001b[33mloaded\u001b[39m\u001b[33m\"\u001b[39m, fname=fname)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Oihane\\Desktop\\NLP\\Entrega2\\venv\\Lib\\site-packages\\gensim\\utils.py:1460\u001b[39m, in \u001b[36munpickle\u001b[39m\u001b[34m(fname)\u001b[39m\n\u001b[32m   1446\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Load object from `fname`, using smart_open so that `fname` can be on S3, HDFS, compressed etc.\u001b[39;00m\n\u001b[32m   1447\u001b[39m \n\u001b[32m   1448\u001b[39m \u001b[33;03mParameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1457\u001b[39m \n\u001b[32m   1458\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1459\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(fname, \u001b[33m'\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m-> \u001b[39m\u001b[32m1460\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_pickle\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlatin1\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Oihane\\Desktop\\NLP\\Entrega2\\venv\\Lib\\site-packages\\numpy\\random\\_pickle.py:34\u001b[39m, in \u001b[36m__bit_generator_ctor\u001b[39m\u001b[34m(bit_generator_name)\u001b[39m\n\u001b[32m     32\u001b[39m     bit_generator = BitGenerators[bit_generator_name]\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;28mstr\u001b[39m(bit_generator_name) + \u001b[33m'\u001b[39m\u001b[33m is not a known \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     35\u001b[39m                                                \u001b[33m'\u001b[39m\u001b[33mBitGenerator module.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m bit_generator()\n",
      "\u001b[31mValueError\u001b[39m: <class 'numpy.random._mt19937.MT19937'> is not a known BitGenerator module."
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "w2v = Word2Vec.load(\"../diplomacy/models/embeddings/word2vec.model\")\n",
    "\n",
    "print(len(w2v.wv.key_to_index))\n",
    "list(w2v.wv.key_to_index.keys())[:50]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
