{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "241ac301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>messages</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>tokens</th>\n",
       "      <th>lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Germany!\\n\\nJust the person I want to speak wi...</td>\n",
       "      <td>germany just the person i want to speak with i...</td>\n",
       "      <td>['germany', 'person', 'want', 'speak', 'somewh...</td>\n",
       "      <td>['germany', 'person', 'want', 'speak', 'somewh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You've whet my appetite, Italy. What's the sug...</td>\n",
       "      <td>youve whet my appetite italy whats the suggestion</td>\n",
       "      <td>['ve', 'whet', 'appetite', 'italy', 's', 'sugg...</td>\n",
       "      <td>['ve', 'whet', 'appetite', 'italy', 's', 'sugg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It seems like there are a lot of ways that cou...</td>\n",
       "      <td>it seems like there are a lot of ways that cou...</td>\n",
       "      <td>['like', 'lot', 'ways', 'wrong', 'nt', 'france...</td>\n",
       "      <td>['like', 'lot', 'way', 'wrong', 'not', 'france...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yeah, I can’t say I’ve tried it and it works, ...</td>\n",
       "      <td>yeah i can t say i ve tried it and it works ca...</td>\n",
       "      <td>['yeah', 't', 've', 'tried', 'works', 'cause',...</td>\n",
       "      <td>['yeah', 't', 've', 'try', 'work', 'cause', 'v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I am just sensing that you don’t like this ide...</td>\n",
       "      <td>i am just sensing that you don t like this ide...</td>\n",
       "      <td>['sensing', 'don', 't', 'like', 'idea', 'shall...</td>\n",
       "      <td>['sense', 'don', 't', 'like', 'idea', 'shall',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Any thoughts?</td>\n",
       "      <td>any thoughts</td>\n",
       "      <td>['thoughts']</td>\n",
       "      <td>['thought']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sorry Italy I've been away doing, um, German t...</td>\n",
       "      <td>sorry italy ive been away doing um german thin...</td>\n",
       "      <td>['sorry', 'italy', 've', 'away', 'um', 'german...</td>\n",
       "      <td>['sorry', 'italy', 've', 'away', 'um', 'german...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I don't think I'm ready to go for that idea, h...</td>\n",
       "      <td>i dont think im ready to go for that idea howe...</td>\n",
       "      <td>['nt', 'think', 'm', 'ready', 'idea', 'd', 'go...</td>\n",
       "      <td>['not', 'think', 'm', 'ready', 'idea', 'd', 'g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>But I think I can get over “Lagergate” and we ...</td>\n",
       "      <td>but i think i can get over lagergate and we ca...</td>\n",
       "      <td>['think', 'lagergate', 'friends', 'right', 'th...</td>\n",
       "      <td>['think', 'lagergate', 'friend', 'right', 'thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>We haven't even passed a season yet and you ha...</td>\n",
       "      <td>we havent even passed a season yet and you hav...</td>\n",
       "      <td>['nt', 'passed', 'season', 'reliable', 'ally',...</td>\n",
       "      <td>['not', 'pass', 'season', 'reliable', 'ally', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            messages  \\\n",
       "0  Germany!\\n\\nJust the person I want to speak wi...   \n",
       "1  You've whet my appetite, Italy. What's the sug...   \n",
       "2  It seems like there are a lot of ways that cou...   \n",
       "3  Yeah, I can’t say I’ve tried it and it works, ...   \n",
       "4  I am just sensing that you don’t like this ide...   \n",
       "5                                      Any thoughts?   \n",
       "6  Sorry Italy I've been away doing, um, German t...   \n",
       "7  I don't think I'm ready to go for that idea, h...   \n",
       "8  But I think I can get over “Lagergate” and we ...   \n",
       "9  We haven't even passed a season yet and you ha...   \n",
       "\n",
       "                                          text_clean  \\\n",
       "0  germany just the person i want to speak with i...   \n",
       "1  youve whet my appetite italy whats the suggestion   \n",
       "2  it seems like there are a lot of ways that cou...   \n",
       "3  yeah i can t say i ve tried it and it works ca...   \n",
       "4  i am just sensing that you don t like this ide...   \n",
       "5                                       any thoughts   \n",
       "6  sorry italy ive been away doing um german thin...   \n",
       "7  i dont think im ready to go for that idea howe...   \n",
       "8  but i think i can get over lagergate and we ca...   \n",
       "9  we havent even passed a season yet and you hav...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  ['germany', 'person', 'want', 'speak', 'somewh...   \n",
       "1  ['ve', 'whet', 'appetite', 'italy', 's', 'sugg...   \n",
       "2  ['like', 'lot', 'ways', 'wrong', 'nt', 'france...   \n",
       "3  ['yeah', 't', 've', 'tried', 'works', 'cause',...   \n",
       "4  ['sensing', 'don', 't', 'like', 'idea', 'shall...   \n",
       "5                                       ['thoughts']   \n",
       "6  ['sorry', 'italy', 've', 'away', 'um', 'german...   \n",
       "7  ['nt', 'think', 'm', 'ready', 'idea', 'd', 'go...   \n",
       "8  ['think', 'lagergate', 'friends', 'right', 'th...   \n",
       "9  ['nt', 'passed', 'season', 'reliable', 'ally',...   \n",
       "\n",
       "                                              lemmas  \n",
       "0  ['germany', 'person', 'want', 'speak', 'somewh...  \n",
       "1  ['ve', 'whet', 'appetite', 'italy', 's', 'sugg...  \n",
       "2  ['like', 'lot', 'way', 'wrong', 'not', 'france...  \n",
       "3  ['yeah', 't', 've', 'try', 'work', 'cause', 'v...  \n",
       "4  ['sense', 'don', 't', 'like', 'idea', 'shall',...  \n",
       "5                                        ['thought']  \n",
       "6  ['sorry', 'italy', 've', 'away', 'um', 'german...  \n",
       "7  ['not', 'think', 'm', 'ready', 'idea', 'd', 'g...  \n",
       "8  ['think', 'lagergate', 'friend', 'right', 'thi...  \n",
       "9  ['not', 'pass', 'season', 'reliable', 'ally', ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Primero vemos algunas filas del texto preprocesado\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet(\"../data/train_preprocessed.parquet\")\n",
    "df.head(10)[[\"messages\", \"text_clean\", \"tokens\", \"lemmas\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3bd2d2b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>messages</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>tokens</th>\n",
       "      <th>lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Germany!\\n\\nJust the person I want to speak wi...</td>\n",
       "      <td>germany just the person i want to speak with i...</td>\n",
       "      <td>['germany', 'person', 'want', 'speak', 'somewh...</td>\n",
       "      <td>['germany', 'person', 'want', 'speak', 'somewh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You've whet my appetite, Italy. What's the sug...</td>\n",
       "      <td>youve whet my appetite italy whats the suggestion</td>\n",
       "      <td>['ve', 'whet', 'appetite', 'italy', 's', 'sugg...</td>\n",
       "      <td>['ve', 'whet', 'appetite', 'italy', 's', 'sugg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It seems like there are a lot of ways that cou...</td>\n",
       "      <td>it seems like there are a lot of ways that cou...</td>\n",
       "      <td>['like', 'lot', 'ways', 'wrong', 'nt', 'france...</td>\n",
       "      <td>['like', 'lot', 'way', 'wrong', 'not', 'france...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yeah, I can’t say I’ve tried it and it works, ...</td>\n",
       "      <td>yeah i can t say i ve tried it and it works ca...</td>\n",
       "      <td>['yeah', 't', 've', 'tried', 'works', 'cause',...</td>\n",
       "      <td>['yeah', 't', 've', 'try', 'work', 'cause', 'v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I am just sensing that you don’t like this ide...</td>\n",
       "      <td>i am just sensing that you don t like this ide...</td>\n",
       "      <td>['sensing', 'don', 't', 'like', 'idea', 'shall...</td>\n",
       "      <td>['sense', 'don', 't', 'like', 'idea', 'shall',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Any thoughts?</td>\n",
       "      <td>any thoughts</td>\n",
       "      <td>['thoughts']</td>\n",
       "      <td>['thought']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sorry Italy I've been away doing, um, German t...</td>\n",
       "      <td>sorry italy ive been away doing um german thin...</td>\n",
       "      <td>['sorry', 'italy', 've', 'away', 'um', 'german...</td>\n",
       "      <td>['sorry', 'italy', 've', 'away', 'um', 'german...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I don't think I'm ready to go for that idea, h...</td>\n",
       "      <td>i dont think im ready to go for that idea howe...</td>\n",
       "      <td>['nt', 'think', 'm', 'ready', 'idea', 'd', 'go...</td>\n",
       "      <td>['not', 'think', 'm', 'ready', 'idea', 'd', 'g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>But I think I can get over “Lagergate” and we ...</td>\n",
       "      <td>but i think i can get over lagergate and we ca...</td>\n",
       "      <td>['think', 'lagergate', 'friends', 'right', 'th...</td>\n",
       "      <td>['think', 'lagergate', 'friend', 'right', 'thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>We haven't even passed a season yet and you ha...</td>\n",
       "      <td>we havent even passed a season yet and you hav...</td>\n",
       "      <td>['nt', 'passed', 'season', 'reliable', 'ally',...</td>\n",
       "      <td>['not', 'pass', 'season', 'reliable', 'ally', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            messages  \\\n",
       "0  Germany!\\n\\nJust the person I want to speak wi...   \n",
       "1  You've whet my appetite, Italy. What's the sug...   \n",
       "2  It seems like there are a lot of ways that cou...   \n",
       "3  Yeah, I can’t say I’ve tried it and it works, ...   \n",
       "4  I am just sensing that you don’t like this ide...   \n",
       "5                                      Any thoughts?   \n",
       "6  Sorry Italy I've been away doing, um, German t...   \n",
       "7  I don't think I'm ready to go for that idea, h...   \n",
       "8  But I think I can get over “Lagergate” and we ...   \n",
       "9  We haven't even passed a season yet and you ha...   \n",
       "\n",
       "                                          text_clean  \\\n",
       "0  germany just the person i want to speak with i...   \n",
       "1  youve whet my appetite italy whats the suggestion   \n",
       "2  it seems like there are a lot of ways that cou...   \n",
       "3  yeah i can t say i ve tried it and it works ca...   \n",
       "4  i am just sensing that you don t like this ide...   \n",
       "5                                       any thoughts   \n",
       "6  sorry italy ive been away doing um german thin...   \n",
       "7  i dont think im ready to go for that idea howe...   \n",
       "8  but i think i can get over lagergate and we ca...   \n",
       "9  we havent even passed a season yet and you hav...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  ['germany', 'person', 'want', 'speak', 'somewh...   \n",
       "1  ['ve', 'whet', 'appetite', 'italy', 's', 'sugg...   \n",
       "2  ['like', 'lot', 'ways', 'wrong', 'nt', 'france...   \n",
       "3  ['yeah', 't', 've', 'tried', 'works', 'cause',...   \n",
       "4  ['sensing', 'don', 't', 'like', 'idea', 'shall...   \n",
       "5                                       ['thoughts']   \n",
       "6  ['sorry', 'italy', 've', 'away', 'um', 'german...   \n",
       "7  ['nt', 'think', 'm', 'ready', 'idea', 'd', 'go...   \n",
       "8  ['think', 'lagergate', 'friends', 'right', 'th...   \n",
       "9  ['nt', 'passed', 'season', 'reliable', 'ally',...   \n",
       "\n",
       "                                              lemmas  \n",
       "0  ['germany', 'person', 'want', 'speak', 'somewh...  \n",
       "1  ['ve', 'whet', 'appetite', 'italy', 's', 'sugg...  \n",
       "2  ['like', 'lot', 'way', 'wrong', 'not', 'france...  \n",
       "3  ['yeah', 't', 've', 'try', 'work', 'cause', 'v...  \n",
       "4  ['sense', 'don', 't', 'like', 'idea', 'shall',...  \n",
       "5                                        ['thought']  \n",
       "6  ['sorry', 'italy', 've', 'away', 'um', 'german...  \n",
       "7  ['not', 'think', 'm', 'ready', 'idea', 'd', 'g...  \n",
       "8  ['think', 'lagergate', 'friend', 'right', 'thi...  \n",
       "9  ['not', 'pass', 'season', 'reliable', 'ally', ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Volvemos a visualizar algunas lineas del texto procesado despues de arreglar los errores(emojis y letras sueltas)\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet(\"../data/train_preprocessed.parquet\")\n",
    "df.head(10)[[\"messages\", \"text_clean\", \"tokens\", \"lemmas\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a926a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulario BoW: 8950\n",
      "Vocabulario TF-IDF: 8950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['germany',\n",
       " 'just',\n",
       " 'the',\n",
       " 'person',\n",
       " 'want',\n",
       " 'to',\n",
       " 'speak',\n",
       " 'with',\n",
       " 'have',\n",
       " 'somewhat',\n",
       " 'crazy',\n",
       " 'idea',\n",
       " 'that',\n",
       " 've',\n",
       " 'always',\n",
       " 'wanted',\n",
       " 'try',\n",
       " 'but',\n",
       " 'never',\n",
       " 'actually']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ahora vemos el tamaño del vocabulario de los modelos BoW y TF-IDF\n",
    "import joblib\n",
    "cv = joblib.load(\"../diplomacy/models/representations/bow_vectorizer.joblib\")\n",
    "tfidf = joblib.load(\"../diplomacy/models/representations/tfidf_vectorizer.joblib\")\n",
    "\n",
    "print(\"Vocabulario BoW:\", len(cv.vocabulary_))\n",
    "print(\"Vocabulario TF-IDF:\", len(tfidf.vocabulary_))\n",
    "\n",
    "# Mostrar algunas palabras del vocabulario\n",
    "list(cv.vocabulary_.keys())[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c0dfd34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del vocabulario Word2Vec: 2025\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('cut', 0.8592541217803955),\n",
       " ('supporting', 0.8437879085540771),\n",
       " ('supported', 0.839428722858429),\n",
       " ('supports', 0.8161010146141052),\n",
       " ('bump', 0.8006856441497803)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vamos a ver ejemplos de embeddings Word2Vec\n",
    "from gensim.models import Word2Vec\n",
    "w2v = Word2Vec.load(\"../diplomacy/models/embeddings/word2vec.model\")\n",
    "\n",
    "# Número de palabras aprendidas\n",
    "print(\"Tamaño del vocabulario Word2Vec:\", len(w2v.wv.key_to_index))\n",
    "\n",
    "# Ver los términos más similares a una palabra\n",
    "w2v.wv.most_similar(\"support\", topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d57ad64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('attacks', 0.9859697222709656),\n",
       " ('supply', 0.9812034368515015),\n",
       " ('supposedly', 0.9783168435096741),\n",
       " ('supposed', 0.9766971468925476),\n",
       " ('suppose', 0.9713596105575562)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ahora vemos ejemplos de embeddings FastText \n",
    "from gensim.models import FastText\n",
    "ft = FastText.load(\"../diplomacy/models/embeddings/fasttext.model\")\n",
    "ft.wv.most_similar(\"attack\", topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98db8d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape BERT embeddings: (11894, 768)\n"
     ]
    }
   ],
   "source": [
    "# Ahora vemos la forma de los embeddings BERT\n",
    "import numpy as np\n",
    "\n",
    "bert_train = np.load(\"../diplomacy/models/embeddings/bert_train.npy\")\n",
    "print(\"Shape BERT embeddings:\", bert_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5753b572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cobertura Word2Vec (después de limpieza): 92.13%\n",
      "\n",
      "Palabras OOV más frecuentes:\n",
      "approaching     4\n",
      "hop             4\n",
      "explicitly      4\n",
      "weakening       4\n",
      "informed        4\n",
      "woke            4\n",
      "bridge          4\n",
      "explanation     4\n",
      "sets            4\n",
      "argument        4\n",
      "willingness     4\n",
      "history         4\n",
      "confidence      4\n",
      "encouraging     4\n",
      "betraying       4\n"
     ]
    }
   ],
   "source": [
    "# Medimos la cobertura de los modelos de embeddings\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "# Función auxiliar para medir cobertura\n",
    "def compute_coverage(tokens_list, model):\n",
    "    total, covered = 0, 0\n",
    "    oov = Counter()\n",
    "    for tokens in tokens_list:\n",
    "        for t in tokens:\n",
    "            total += 1\n",
    "            if t in model.wv:\n",
    "                covered += 1\n",
    "            else:\n",
    "                oov[t] += 1\n",
    "    coverage = covered / total * 100\n",
    "    return coverage, oov\n",
    "\n",
    "# Cargar dataset preprocesado\n",
    "df = pd.read_parquet(\"../data/train_preprocessed.parquet\")\n",
    "\n",
    "# Asegurar que tokens sean listas (no strings)\n",
    "if isinstance(df[\"tokens\"].iloc[0], str):\n",
    "    df[\"tokens\"] = df[\"tokens\"].apply(ast.literal_eval)\n",
    "\n",
    "w2v = Word2Vec.load(\"../diplomacy/models/embeddings/word2vec.model\")\n",
    "new_coverage, new_oov = compute_coverage(df[\"tokens\"], w2v)\n",
    "print(f\"Cobertura Word2Vec (después de limpieza): {new_coverage:.2f}%\")\n",
    "\n",
    "# Mostrar algunas palabras fuera del vocabulario\n",
    "print(\"\\nPalabras OOV más frecuentes:\")\n",
    "for word, count in new_oov.most_common(15):\n",
    "    print(f\"{word:<15} {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30157a57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    11894.000000\n",
       "mean        75.943165\n",
       "std         74.447143\n",
       "min          2.000000\n",
       "25%         28.000000\n",
       "50%         54.000000\n",
       "75%         99.000000\n",
       "max       1098.000000\n",
       "Name: len_tokens, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finalmente, vemos la distribución de la longitud de los textos en tokens\n",
    "df[\"len_tokens\"] = df[\"tokens\"].apply(len)\n",
    "df[\"len_tokens\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a74f15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       104\n",
      "           1       0.96      1.00      0.98      2275\n",
      "\n",
      "    accuracy                           0.96      2379\n",
      "   macro avg       0.48      0.50      0.49      2379\n",
      "weighted avg       0.91      0.96      0.93      2379\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Oihane\\Desktop\\NLP\\Entrega2\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\Oihane\\Desktop\\NLP\\Entrega2\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\Oihane\\Desktop\\NLP\\Entrega2\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# Visualización de la distribución\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import scipy.sparse as sp\n",
    "\n",
    "# Cargar TF-IDF\n",
    "X = sp.load_npz(\"../diplomacy/models/representations/X_tfidf_train.npz\")\n",
    "y = pd.read_parquet(\"../data/train_preprocessed.parquet\")[\"sender_labels\"]\n",
    "\n",
    "# Convertir etiquetas a numéricas\n",
    "y = (y == \"True\").astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
