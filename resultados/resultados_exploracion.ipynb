{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "241ac301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>messages</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>tokens</th>\n",
       "      <th>lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Germany!\\n\\nJust the person I want to speak wi...</td>\n",
       "      <td>germany just the person i want to speak with i...</td>\n",
       "      <td>['germany', 'person', 'want', 'speak', 'somewh...</td>\n",
       "      <td>['germany', 'person', 'want', 'speak', 'somewh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You've whet my appetite, Italy. What's the sug...</td>\n",
       "      <td>you ve whet my appetite italy what s the sugge...</td>\n",
       "      <td>['ve', 'whet', 'appetite', 'italy', 's', 'sugg...</td>\n",
       "      <td>['ve', 'whet', 'appetite', 'italy', 's', 'sugg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>üëç</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It seems like there are a lot of ways that cou...</td>\n",
       "      <td>it seems like there are a lot of ways that cou...</td>\n",
       "      <td>['like', 'lot', 'ways', 'wrong', 'don', 't', '...</td>\n",
       "      <td>['like', 'lot', 'way', 'wrong', 'don', 't', 'f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yeah, I can‚Äôt say I‚Äôve tried it and it works, ...</td>\n",
       "      <td>yeah i can t say i ve tried it and it works ca...</td>\n",
       "      <td>['yeah', 't', 've', 'tried', 'works', 'cause',...</td>\n",
       "      <td>['yeah', 't', 've', 'try', 'work', 'cause', 'v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I am just sensing that you don‚Äôt like this ide...</td>\n",
       "      <td>i am just sensing that you don t like this ide...</td>\n",
       "      <td>['sensing', 'don', 't', 'like', 'idea', 'shall...</td>\n",
       "      <td>['sense', 'don', 't', 'like', 'idea', 'shall',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Any thoughts?</td>\n",
       "      <td>any thoughts</td>\n",
       "      <td>['thoughts']</td>\n",
       "      <td>['thought']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sorry Italy I've been away doing, um, German t...</td>\n",
       "      <td>sorry italy i ve been away doing um german thi...</td>\n",
       "      <td>['sorry', 'italy', 've', 'away', 'um', 'german...</td>\n",
       "      <td>['sorry', 'italy', 've', 'away', 'um', 'german...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I don't think I'm ready to go for that idea, h...</td>\n",
       "      <td>i don t think i m ready to go for that idea ho...</td>\n",
       "      <td>['don', 't', 'think', 'm', 'ready', 'idea', 'd...</td>\n",
       "      <td>['don', 't', 'think', 'm', 'ready', 'idea', 'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I am pretty conflicted about whether to guess ...</td>\n",
       "      <td>i am pretty conflicted about whether to guess ...</td>\n",
       "      <td>['pretty', 'conflicted', 'guess', 'telling', '...</td>\n",
       "      <td>['pretty', 'conflicted', 'guess', 'tell', 'tru...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            messages  \\\n",
       "0  Germany!\\n\\nJust the person I want to speak wi...   \n",
       "1  You've whet my appetite, Italy. What's the sug...   \n",
       "2                                                  üëç   \n",
       "3  It seems like there are a lot of ways that cou...   \n",
       "4  Yeah, I can‚Äôt say I‚Äôve tried it and it works, ...   \n",
       "5  I am just sensing that you don‚Äôt like this ide...   \n",
       "6                                      Any thoughts?   \n",
       "7  Sorry Italy I've been away doing, um, German t...   \n",
       "8  I don't think I'm ready to go for that idea, h...   \n",
       "9  I am pretty conflicted about whether to guess ...   \n",
       "\n",
       "                                          text_clean  \\\n",
       "0  germany just the person i want to speak with i...   \n",
       "1  you ve whet my appetite italy what s the sugge...   \n",
       "2                                                      \n",
       "3  it seems like there are a lot of ways that cou...   \n",
       "4  yeah i can t say i ve tried it and it works ca...   \n",
       "5  i am just sensing that you don t like this ide...   \n",
       "6                                       any thoughts   \n",
       "7  sorry italy i ve been away doing um german thi...   \n",
       "8  i don t think i m ready to go for that idea ho...   \n",
       "9  i am pretty conflicted about whether to guess ...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  ['germany', 'person', 'want', 'speak', 'somewh...   \n",
       "1  ['ve', 'whet', 'appetite', 'italy', 's', 'sugg...   \n",
       "2                                                 []   \n",
       "3  ['like', 'lot', 'ways', 'wrong', 'don', 't', '...   \n",
       "4  ['yeah', 't', 've', 'tried', 'works', 'cause',...   \n",
       "5  ['sensing', 'don', 't', 'like', 'idea', 'shall...   \n",
       "6                                       ['thoughts']   \n",
       "7  ['sorry', 'italy', 've', 'away', 'um', 'german...   \n",
       "8  ['don', 't', 'think', 'm', 'ready', 'idea', 'd...   \n",
       "9  ['pretty', 'conflicted', 'guess', 'telling', '...   \n",
       "\n",
       "                                              lemmas  \n",
       "0  ['germany', 'person', 'want', 'speak', 'somewh...  \n",
       "1  ['ve', 'whet', 'appetite', 'italy', 's', 'sugg...  \n",
       "2                                                 []  \n",
       "3  ['like', 'lot', 'way', 'wrong', 'don', 't', 'f...  \n",
       "4  ['yeah', 't', 've', 'try', 'work', 'cause', 'v...  \n",
       "5  ['sense', 'don', 't', 'like', 'idea', 'shall',...  \n",
       "6                                        ['thought']  \n",
       "7  ['sorry', 'italy', 've', 'away', 'um', 'german...  \n",
       "8  ['don', 't', 'think', 'm', 'ready', 'idea', 'd...  \n",
       "9  ['pretty', 'conflicted', 'guess', 'tell', 'tru...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Primero vemos algunas filas del texto preprocesado\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet(\"../data/train_preprocessed.parquet\")\n",
    "df.head(10)[[\"messages\", \"text_clean\", \"tokens\", \"lemmas\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a926a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulario BoW: 10434\n",
      "Vocabulario TF-IDF: 10434\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['germany',\n",
       " 'just',\n",
       " 'the',\n",
       " 'person',\n",
       " 'want',\n",
       " 'to',\n",
       " 'speak',\n",
       " 'with',\n",
       " 'have',\n",
       " 'somewhat',\n",
       " 'crazy',\n",
       " 'idea',\n",
       " 'that',\n",
       " 've',\n",
       " 'always',\n",
       " 'wanted',\n",
       " 'try',\n",
       " 'but',\n",
       " 'never',\n",
       " 'actually']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ahora vemos el tama√±o del vocabulario de los modelos BoW y TF-IDF\n",
    "import joblib\n",
    "cv = joblib.load(\"../diplomacy/models/representations/bow_vectorizer.joblib\")\n",
    "tfidf = joblib.load(\"../diplomacy/models/representations/tfidf_vectorizer.joblib\")\n",
    "\n",
    "print(\"Vocabulario BoW:\", len(cv.vocabulary_))\n",
    "print(\"Vocabulario TF-IDF:\", len(tfidf.vocabulary_))\n",
    "\n",
    "# Mostrar algunas palabras del vocabulario\n",
    "list(cv.vocabulary_.keys())[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c0dfd34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tama√±o del vocabulario Word2Vec: 2261\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('cut', 0.8187794089317322),\n",
       " ('supported', 0.8015599846839905),\n",
       " ('supporting', 0.7948482632637024),\n",
       " ('bump', 0.7930293679237366),\n",
       " ('supports', 0.7880041003227234)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vamos a ver ejemplos de embeddings Word2Vec\n",
    "from gensim.models import Word2Vec\n",
    "w2v = Word2Vec.load(\"../diplomacy/models/embeddings/word2vec.model\")\n",
    "\n",
    "# N√∫mero de palabras aprendidas\n",
    "print(\"Tama√±o del vocabulario Word2Vec:\", len(w2v.wv.key_to_index))\n",
    "\n",
    "# Ver los t√©rminos m√°s similares a una palabra\n",
    "w2v.wv.most_similar(\"support\", topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2d57ad64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('attacks', 0.9825449585914612),\n",
       " ('supply', 0.9691567420959473),\n",
       " ('need', 0.9537312388420105),\n",
       " ('supposed', 0.9504920840263367),\n",
       " ('sup', 0.9486726522445679)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ahora vemos ejemplos de embeddings FastText \n",
    "from gensim.models import FastText\n",
    "ft = FastText.load(\"../diplomacy/models/embeddings/fasttext.model\")\n",
    "ft.wv.most_similar(\"attack\", topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98db8d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape BERT embeddings: (13137, 768)\n"
     ]
    }
   ],
   "source": [
    "# Ahora vemos la forma de los embeddings BERT\n",
    "import numpy as np\n",
    "\n",
    "bert_train = np.load(\"../diplomacy/models/embeddings/bert_train.npy\")\n",
    "print(\"Shape BERT embeddings:\", bert_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd3cf58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cobertura Word2Vec: 39.62 %\n",
      "Palabras OOV m√°s frecuentes: [(\"'\", 239414), (',', 106791), (' ', 106791), ('n', 50253), ('a', 49666), ('i', 43434), ('l', 35197), ('[', 13137), (']', 13137), ('x', 739)]\n"
     ]
    }
   ],
   "source": [
    "# Ahora calculamos la cobertura del vocabulario Word2Vec\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "def compute_coverage(tokens_list, model):\n",
    "    total, covered = 0, 0\n",
    "    oov = Counter()\n",
    "    for tokens in tokens_list:\n",
    "        for t in tokens:\n",
    "            total += 1\n",
    "            if t in model.wv:\n",
    "                covered += 1\n",
    "            else:\n",
    "                oov[t] += 1\n",
    "    return covered / total, oov\n",
    "\n",
    "df = pd.read_parquet(\"../data/train_preprocessed.parquet\")\n",
    "coverage, oov = compute_coverage(df[\"tokens\"], w2v)\n",
    "print(\"Cobertura Word2Vec:\", round(coverage * 100, 2), \"%\")\n",
    "print(\"Palabras OOV m√°s frecuentes:\", oov.most_common(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30157a57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    13137.000000\n",
       "mean        83.171729\n",
       "std         88.711164\n",
       "min          2.000000\n",
       "25%         28.000000\n",
       "50%         56.000000\n",
       "75%        106.000000\n",
       "max       1127.000000\n",
       "Name: len_tokens, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finalmente, vemos la distribuci√≥n de la longitud de los textos en tokens\n",
    "df[\"len_tokens\"] = df[\"tokens\"].apply(len)\n",
    "df[\"len_tokens\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6a74f15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       119\n",
      "           1       0.95      1.00      0.98      2509\n",
      "\n",
      "    accuracy                           0.95      2628\n",
      "   macro avg       0.48      0.50      0.49      2628\n",
      "weighted avg       0.91      0.95      0.93      2628\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Oihane\\Desktop\\NLP\\Entrega2\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\Oihane\\Desktop\\NLP\\Entrega2\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\Oihane\\Desktop\\NLP\\Entrega2\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import scipy.sparse as sp\n",
    "\n",
    "# Cargar TF-IDF\n",
    "X = sp.load_npz(\"../diplomacy/models/representations/X_tfidf_train.npz\")\n",
    "y = pd.read_parquet(\"../data/train_preprocessed.parquet\")[\"sender_labels\"]\n",
    "\n",
    "# Convertir etiquetas a num√©ricas\n",
    "y = (y == \"True\").astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
